{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import cvzone\n",
    "import torch\n",
    "\n",
    "\n",
    "import easyocr\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "import pathlib\n",
    "temp = pathlib.PosixPath\n",
    "pathlib.PosixPath = pathlib.WindowsPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_number_plate(img, ocr):\n",
    "    result = ocr.ocr(img, cls=True)\n",
    "    result = result[0]\n",
    "    texts = [line[1][0] for line in result]\n",
    "    scores = [line[1][1] for line in result]\n",
    "    if (scores[0]*100) >= 90:\n",
    "        return re.sub(r'[^a-zA-Z0-9]', '', texts[0]), scores[0]\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2024-4-26 Python-3.10.0 torch-2.3.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 1800x1036 3 without helmets, 2 riders, 2 number plates\n",
      "Speed: 7.8ms pre-process, 179.9ms inference, 0.0ms NMS per image at shape (1, 3, 640, 384)\n",
      "image 1/1: 708x406 1 with helmet, 1 number plate\n",
      "Speed: 4.0ms pre-process, 168.0ms inference, 0.0ms NMS per image at shape (1, 3, 640, 384)\n",
      "image 1/1: 1064x954 1 with helmet, 1 number plate\n",
      "Speed: 4.5ms pre-process, 251.7ms inference, 1.3ms NMS per image at shape (1, 3, 640, 576)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"train/images/new53.jpg\")  # For videos\n",
    "\n",
    "model =  torch.hub.load('./yolov5', 'custom', source ='local', path='best.pt',force_reload=False)\n",
    "\n",
    "device = torch.device(\"mps\") # change to cuda for windows gpu\n",
    "\n",
    "classNames = [\"with helmet\", \"without helmet\", \"rider\", \"number plate\"]\n",
    "num = 0\n",
    "old_npconf = 0\n",
    "\n",
    "# grab the width, height, and fps of the frames in the video stream.\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# initialize the FourCC and a video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter('output.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "\n",
    "ocr = easyocr.Reader(['en']) # need to run only once to download and load model into memory\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    # Check if the frame was read successfully\n",
    "    if not success:\n",
    "        break\n",
    "    new_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    result = []\n",
    "    results = model([new_img])\n",
    "    result.append(results)\n",
    "    for r in result:\n",
    "        print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'with helmet', 1: 'without helmet', 2: 'rider', 3: 'number plate'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[3.94783e+02, 7.77288e+02, 5.49848e+02, 8.64148e+02, 7.56493e-01, 3.00000e+00],\n",
       "         [5.89161e+02, 1.04086e+02, 7.68846e+02, 2.20175e+02, 4.82333e-01, 0.00000e+00]])]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[4.72316e+02, 8.20718e+02, 1.55065e+02, 8.68602e+01, 7.56493e-01, 3.00000e+00],\n",
       "         [6.79004e+02, 1.62130e+02, 1.79686e+02, 1.16090e+02, 4.82333e-01, 0.00000e+00]])]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.xywh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.49509, 0.77135, 0.16254, 0.08164, 0.75649, 3.00000],\n",
       "         [0.71174, 0.15238, 0.18835, 0.10911, 0.48233, 0.00000]])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.xywhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.41382, 0.73053, 0.57636, 0.81217, 0.75649, 3.00000],\n",
       "         [0.61757, 0.09782, 0.80592, 0.20693, 0.48233, 0.00000]])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.xyxyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
